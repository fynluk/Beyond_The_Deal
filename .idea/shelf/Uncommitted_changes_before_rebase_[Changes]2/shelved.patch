Index: Final/analysis.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import logging\nimport lseg.data as ld\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom tqdm.contrib.concurrent import process_map\nfrom functools import partial\nfrom IPython.core.display_functions import display\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom scipy.interpolate import griddata\nfrom scipy.stats import linregress\nimport plotly.graph_objects as go\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\n\nclass RunConfig:\n    def __init__(self, universe: str, endDate: str):\n        self.universe = universe\n        self.endDate = endDate\n\n\ndef refinitiv_session():\n    logging.info(\"Connect to Refnitiv\")\n    config = ld.get_config()\n    config.set_param(\"logs.transports.console.enabled\", True)\n    config.set_param(\"logs.level\", \"info\")\n    try:\n        ld.open_session()\n    except Exception as ex:\n        logging.error(ex)\n        logging.error(\"Failed to connect to Refnitiv\")\n        exit(1)\n\ndef get_universe(config: RunConfig):\n    logging.info(\"Get Tickers from Index\")\n    try:\n        query = ld.get_data(\n        universe=config.universe,\n        fields=['TR.RIC'],\n        parameters={'SDate': config.endDate        }\n        )\n        del query['RIC']\n        return set(query['Instrument'].dropna().to_list()), query['Instrument'].dropna()\n    except Exception as ex:\n        logging.error(ex)\n        logging.error(\"Failed to get Tickers from Index\")\n        exit(1)\n\ndef get_data(config: RunConfig, universe: set, frq: str):\n    logging.info(\"Get Data from Refinitiv\")\n\n    date = datetime.strptime(config.endDate, \"%Y-%m-%d\")\n    if frq == \"W\":\n        new_date = date - relativedelta(years=2) + relativedelta(days=1)\n        startDate = new_date.strftime(\"%Y-%m-%d\")\n    elif frq == \"M\":\n        new_date = date - relativedelta(years=5) + relativedelta(days=1)\n        startDate = new_date.strftime(\"%Y-%m-%d\")\n    else:\n        logging.error(\"Invalid frq\")\n        exit(1)\n\n    if True:\n        prices = ld.get_data(\n            universe=universe,\n            fields=[\"TR.PriceClose\",\"TR.PriceClose.date\"],\n            parameters={\n                \"Frq\": frq,\n                \"SDate\": startDate,\n                \"EDate\": config.endDate\n            }\n        )\n        esg = ld.get_data(\n            universe=universe,\n            fields=[\"TR.TRESGScore\", \"TR.TRESGScore.date\"],\n            parameters={\n                \"SDate\": startDate\n            }\n        )\n        prices.columns = [\"Instrument\", \"Price Close\", \"Date\"]\n        esg.columns = [\"Instrument\", \"ESG Score\", \"Date\"]\n\n        mask_na = esg[\"Date\"].isna() | esg[\"ESG Score\"].isna()\n        instruments_dropped = esg.loc[mask_na, \"Instrument\"].unique()\n        print(instruments_dropped)\n        print(type(instruments_dropped))\n\n        esg_dropped = esg.dropna()\n        esg_dropped[\"Date\"] = pd.to_datetime(esg_dropped[\"Date\"])\n        display(esg_dropped)\n        latest_esg = (\n            esg_dropped\n            .loc[esg_dropped.groupby(\"Instrument\")[\"Date\"].idxmax()]\n            .sort_values(\"Instrument\")\n            .reset_index(drop=True)\n        )\n\n        prices_pivot = prices.dropna().pivot(index=\"Date\", columns=\"Instrument\", values=\"Price Close\")\n        return prices_pivot, latest_esg\n\ndef main():\n    config = RunConfig(universe=\"0#.SPX\", endDate=\"2025-12-31\")\n    refinitiv_session()\n    universe, df_universe = get_universe(config)\n    prices5Y, esg5Y = get_data(config, universe, \"M\")\n    prices2Y, esg2Y = get_data(config, universe, \"W\")\n\n    logging.info(\"Save data to csv\")\n    dataframes_to_save = [\n        ('01-Universe', df_universe),\n        ('02-Prices5Y', prices5Y),\n        ('03-ESG5Y', esg5Y),\n        ('04-Prices2Y', prices2Y),\n        ('05-ESG2Y', esg2Y),\n    ]\n\n    # Speichern als CSV\n    for name, df in dataframes_to_save:\n        df.to_csv(f'Data/{name}.csv', index=True)\n\nif __name__ == '__main__':\n    pd.set_option('future.no_silent_downcasting', True)\n    logging.basicConfig(\n        level=logging.INFO,\n        filename= 'runtime.log',\n        filemode='w',\n        format='%(asctime)s %(levelname)s %(message)s'\n    )\n    main()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Final/analysis.py b/Final/analysis.py
--- a/Final/analysis.py	(revision 270a09f38f40945b68529209862c879a746b06c2)
+++ b/Final/analysis.py	(date 1768152111494)
@@ -86,7 +86,7 @@
         print(instruments_dropped)
         print(type(instruments_dropped))
 
-        esg_dropped = esg.dropna()
+        esg_dropped = esg.dropna().copy()
         esg_dropped["Date"] = pd.to_datetime(esg_dropped["Date"])
         display(esg_dropped)
         latest_esg = (
